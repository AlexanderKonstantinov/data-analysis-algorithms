{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rules\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from datetime import datetime \n",
    "from sklearn.metrics import r2_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача: предсказать средний балл на экзамене по математике"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка тренировочной выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "last_index = data.shape[0] - 1\n",
    "\n",
    "X = np.array(data.iloc[0:last_index, 2:7].copy())\n",
    "y = np.array(data.iloc[0:last_index, 11].copy())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "# random_state =j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуем класс узла\n",
    "\n",
    "class Node:\n",
    "    \n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index  # индекс признака, по которому ведется сравнение с порогом в этом узле\n",
    "        self.t = t  # значение порога\n",
    "        self.true_branch = true_branch  # поддерево, удовлетворяющее условию в узле\n",
    "        self.false_branch = false_branch  # поддерево, не удовлетворяющее условию в узле\n",
    "        \n",
    "# И класс терминального узла (листа)\n",
    "\n",
    "class Leaf:\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.prediction = self.predict()\n",
    "        \n",
    "    def predict(self):        \n",
    "        return np.mean(self.labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# реализуем генерацию N бутстрап-выборок\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "def get_bootstrap(data, labels, N):\n",
    "    n_samples = data.shape[0]\n",
    "    bootstrap = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        b_data = np.zeros(data.shape)\n",
    "        b_labels = np.zeros(labels.shape)\n",
    "        \n",
    "        for j in range(n_samples):\n",
    "            sample_index = random.randint(0, n_samples-1)\n",
    "            b_data[j] = data[sample_index]\n",
    "            b_labels[j] = labels[sample_index]\n",
    "        bootstrap.append((b_data, b_labels))\n",
    "        \n",
    "    return bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispersion(labels):\n",
    "        \n",
    "    return np.var(labels)\n",
    "\n",
    "\n",
    "def get_subsample(len_sample):\n",
    "    # будем сохранять не сами признаки, а их индексы\n",
    "    sample_indexes = [i for i in range(len_sample)]\n",
    "    \n",
    "    len_subsample = int(np.sqrt(len_sample))\n",
    "    subsample = []\n",
    "    \n",
    "    random.shuffle(sample_indexes)\n",
    "    subsample = sample_indexes[0:len_subsample].copy()\n",
    "#     for _ in range(len_subsample):\n",
    "#         subsample.append(sample_indexes.pop())\n",
    "        \n",
    "    return subsample\n",
    "\n",
    "def mean_squared_error(y_real, prediction):\n",
    "    return (sum((y_real - prediction)**2)) / len(y_real)\n",
    "\n",
    "\n",
    "# Расчет качества\n",
    "\n",
    "def quality(left_labels, right_labels, current_dispersion):\n",
    "\n",
    "    # доля выбоки, ушедшая в левое поддерево\n",
    "    p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
    "    \n",
    "    return current_dispersion - p * dispersion(left_labels) - (1 - p) * dispersion(right_labels)\n",
    "\n",
    "# Разбиение датасета в узле\n",
    "\n",
    "def split(data, labels, index, t):\n",
    "    \n",
    "    left = np.where(data[:, index] <= t)\n",
    "    right = np.where(data[:, index] > t)\n",
    "        \n",
    "    true_data = data[left]\n",
    "    false_data = data[right]\n",
    "    true_labels = labels[left]\n",
    "    false_labels = labels[right]\n",
    "        \n",
    "    return true_data, false_data, true_labels, false_labels\n",
    "\n",
    "# Нахождение наилучшего разбиения\n",
    "\n",
    "def find_best_split(data, labels):\n",
    "    global min_leafs\n",
    "    \n",
    "    min_leafs = 5\n",
    "\n",
    "    current_dispersion = dispersion(labels)\n",
    "\n",
    "    best_quality = 0\n",
    "    best_t = None\n",
    "    best_index = None\n",
    "    \n",
    "    n_features = data.shape[1]\n",
    "    \n",
    "    # выбор индекса из подвыборки длиной sqrt(n_features)\n",
    "    subsample = get_subsample(n_features)\n",
    "    \n",
    "    for index in subsample:\n",
    "        t_values = [row[index] for row in data]\n",
    "        \n",
    "        for t in t_values:\n",
    "            true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "            #  пропускаем разбиения, в которых в узле остается менее 5 объектов\n",
    "            if len(true_data) < min_leafs or len(false_data) < min_leafs:\n",
    "                continue\n",
    "            \n",
    "            current_quality = quality(true_labels, false_labels, current_dispersion)\n",
    "            \n",
    "            #  выбираем порог, на котором получается максимальный прирост качества\n",
    "            if current_quality > best_quality:\n",
    "                best_quality, best_t, best_index = current_quality, t, index\n",
    "\n",
    "    return best_quality, best_t, best_index\n",
    "\n",
    "# Построение дерева с помощью рекурсивной функции\n",
    "\n",
    "def build_tree(data, labels):\n",
    "    global level_count, leaf_count, level_limit, leaf_limit\n",
    "\n",
    "    quality, t, index = find_best_split(data, labels)\n",
    "\n",
    "    #  Базовый случай - прекращаем рекурсию, когда нет прироста в качества\n",
    "#     if quality == 0 or leaf_count + 1 == leaf_limit or level_count == level_limit:    \n",
    "    if quality == 0:        \n",
    "\n",
    "        return Leaf(data, labels)\n",
    "\n",
    "    true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "\n",
    "    # Рекурсивно строим два поддерева\n",
    "    level_count += 1\n",
    "    \n",
    "    leaf_count += 1   \n",
    "    true_branch = build_tree(true_data, true_labels)\n",
    "    leaf_count += 1   \n",
    "    false_branch = build_tree(false_data, false_labels)\n",
    "\n",
    "    # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
    "    return Node(index, t, true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим функцию формирования случайного леса.\n",
    "\n",
    "def random_forest(data, labels, n_trees, n_levels, n_leafs, n_min_leafs):\n",
    "    global level_count, leaf_count, level_limit, leaf_limit, min_leafs    \n",
    "    \n",
    "    level_limit = n_levels\n",
    "    leaf_limit = n_leafs\n",
    "    min_leafs = n_min_leafs\n",
    "    \n",
    "    forest = []\n",
    "    bootstrap = get_bootstrap(data, labels, n_trees)\n",
    "    \n",
    "    for b_data, b_labels in bootstrap:\n",
    "        level_count, leaf_count = 0, 0\n",
    "        forest.append(build_tree(b_data, b_labels))\n",
    "        \n",
    "    return forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция классификации отдельного объекта\n",
    "\n",
    "def predict_object(obj, node):\n",
    "\n",
    "    #  Останавливаем рекурсию, если достигли листа\n",
    "    if isinstance(node, Leaf):\n",
    "        answer = node.prediction\n",
    "        return answer\n",
    "    \n",
    "    if obj[node.index] <= node.t:\n",
    "        return predict_object(obj, node.true_branch)\n",
    "    else:\n",
    "        return predict_object(obj, node.false_branch)\n",
    "\n",
    "# функция формирования предсказания по выборке на одном дереве\n",
    "\n",
    "def predict(data, tree):\n",
    "    \n",
    "    predictions = []\n",
    "    for obj in data:\n",
    "        prediction = predict_object(obj, tree)\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "# предсказание голосованием деревьев\n",
    "\n",
    "def tree_vote(forest, data):\n",
    "\n",
    "    # добавим предсказания всех деревьев в список\n",
    "    answers = []\n",
    "    for tree in forest:\n",
    "        answers.append(predict(data, tree))\n",
    "           \n",
    "    return list(map(np.mean, zip(*answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_alg(X_train, X_test, y_train, y_test, trees, n_trees, n_levels, n_leafs, n_min_leafs, fit_seconds):\n",
    "    \n",
    "    print()    \n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    train_answers = tree_vote(trees, X_train) \n",
    "    predict_seconds = (datetime.now() - start_time).total_seconds()\n",
    "    print(f'train\\t{mean_squared_error(y_train, train_answers):.3f}\\t{n_trees}\\t{n_levels}\\t{n_leafs}\\t{n_min_leafs}\\t{fit_seconds:.3f}\\t{predict_seconds:.3f}\\t{r2_score(y_train, train_answers)}')\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    test_answers = tree_vote(trees, X_test)\n",
    "    predict_seconds = (datetime.now() - start_time).total_seconds()\n",
    "    print(f'test\\t{mean_squared_error(y_test, test_answers):.3f}\\t{n_trees}\\t{n_levels}\\t{n_leafs}\\t{n_min_leafs}\\t{fit_seconds:.3f}\\t{predict_seconds:.3f}\\t{r2_score(y_test, test_answers)}')\n",
    "    \n",
    "    return train_answers, test_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\terror\ttrees\tlevels\tleafs\tobjects\tgb fit\tpredict\tr2\n",
      "\n",
      "train\t38.065\t6\t7\t7\t3\t67.387\t0.205\t0.7879552294226327\n",
      "test\t42.725\t6\t7\t7\t3\t67.387\t0.072\t0.7801517675959991\n",
      "\n",
      "train\t38.612\t6\t7\t7\t4\t65.548\t0.204\t0.7849089353364814\n",
      "test\t42.879\t6\t7\t7\t4\t65.548\t0.072\t0.7793605342619234\n",
      "\n",
      "train\t39.176\t6\t7\t7\t5\t69.500\t0.210\t0.7817641722460851\n",
      "test\t43.176\t6\t7\t7\t5\t69.500\t0.073\t0.7778331641650973\n",
      "\n",
      "train\t39.949\t6\t7\t7\t6\t70.465\t0.246\t0.7774622804519923\n",
      "test\t43.875\t6\t7\t7\t6\t70.465\t0.079\t0.7742325139220168\n",
      "\n",
      "train\t39.154\t6\t7\t7\t7\t80.971\t0.255\t0.7818861811765595\n",
      "test\t44.068\t6\t7\t7\t7\t80.971\t0.089\t0.7732438632292783\n",
      "\n",
      "train\t39.336\t6\t7\t7\t8\t72.499\t0.191\t0.78087266340851\n",
      "test\t43.941\t6\t7\t7\t8\t72.499\t0.071\t0.7738971472069339\n",
      "\n",
      "train\t41.187\t6\t7\t7\t9\t61.906\t0.183\t0.7705638980875233\n",
      "test\t44.805\t6\t7\t7\t9\t61.906\t0.065\t0.7694513940229794\n",
      "\n",
      "train\t37.585\t6\t7\t7\t10\t68.888\t0.205\t0.7906309641621989\n",
      "test\t42.843\t6\t7\t7\t10\t68.888\t0.073\t0.7795465009155419\n",
      "\n",
      "train\t41.790\t6\t7\t7\t11\t63.864\t0.189\t0.7672014889900645\n",
      "test\t45.812\t6\t7\t7\t11\t63.864\t0.067\t0.7642674014798064\n",
      "\n",
      "train\t38.936\t6\t7\t7\t12\t63.509\t0.202\t0.7831015476303231\n",
      "test\t43.554\t6\t7\t7\t12\t63.509\t0.070\t0.7758862405492112\n",
      "\n",
      "train\t39.520\t6\t7\t8\t3\t63.319\t0.237\t0.7798522395806401\n",
      "test\t43.705\t6\t7\t8\t3\t63.319\t0.084\t0.7751097969956239\n",
      "\n",
      "train\t39.609\t6\t7\t8\t4\t65.782\t0.198\t0.7793513703790658\n",
      "test\t43.586\t6\t7\t8\t4\t65.782\t0.071\t0.775719987172003\n",
      "\n",
      "train\t38.719\t6\t7\t8\t5\t66.535\t0.195\t0.7843125470270007\n",
      "test\t42.264\t6\t7\t8\t5\t66.535\t0.072\t0.7825266481448955\n",
      "\n",
      "train\t37.589\t6\t7\t8\t6\t61.342\t0.197\t0.7906069127118003\n",
      "test\t42.229\t6\t7\t8\t6\t61.342\t0.070\t0.7827033752538324\n",
      "\n",
      "train\t40.045\t6\t7\t8\t7\t65.740\t0.227\t0.7769234848225495\n",
      "test\t43.771\t6\t7\t8\t7\t65.740\t0.082\t0.7747705268265813\n",
      "\n",
      "train\t38.592\t6\t7\t8\t8\t65.055\t0.195\t0.7850209205188192\n",
      "test\t42.787\t6\t7\t8\t8\t65.055\t0.072\t0.7798331114278556\n",
      "\n",
      "train\t37.497\t6\t7\t8\t9\t68.131\t0.208\t0.7911196768143934\n",
      "test\t42.524\t6\t7\t8\t9\t68.131\t0.074\t0.7811841091773633\n",
      "\n",
      "train\t42.161\t6\t7\t8\t10\t63.368\t0.191\t0.7651379097780465\n",
      "test\t46.360\t6\t7\t8\t10\t63.368\t0.069\t0.7614491547035787\n",
      "\n",
      "train\t38.258\t6\t7\t8\t11\t68.403\t0.197\t0.7868813021045149\n",
      "test\t42.915\t6\t7\t8\t11\t68.403\t0.068\t0.7791759581199812\n",
      "\n",
      "train\t39.437\t6\t7\t8\t12\t63.940\t0.189\t0.7803136592308774\n",
      "test\t43.677\t6\t7\t8\t12\t63.940\t0.069\t0.7752545803167683\n",
      "\n",
      "train\t39.795\t6\t7\t9\t3\t65.235\t0.195\t0.7783151533704682\n",
      "test\t44.771\t6\t7\t9\t3\t65.235\t0.071\t0.7696224845285365\n",
      "\n",
      "train\t39.391\t6\t7\t9\t4\t67.244\t0.199\t0.780565771575824\n",
      "test\t43.228\t6\t7\t9\t4\t67.244\t0.070\t0.7775659179918357\n",
      "\n",
      "train\t40.067\t6\t7\t9\t5\t65.231\t0.188\t0.7768015381002179\n",
      "test\t44.430\t6\t7\t9\t5\t65.231\t0.069\t0.7713813611641915\n",
      "\n",
      "train\t39.632\t6\t7\t9\t6\t62.642\t0.187\t0.7792234500045813\n",
      "test\t43.367\t6\t7\t9\t6\t62.642\t0.066\t0.7768493198156949\n",
      "\n",
      "train\t40.736\t6\t7\t9\t7\t63.344\t0.193\t0.7730756959771493\n",
      "test\t44.904\t6\t7\t9\t7\t63.344\t0.070\t0.7689412128333424\n",
      "\n",
      "train\t39.132\t6\t7\t9\t8\t65.579\t0.195\t0.7820133721009865\n",
      "test\t43.346\t6\t7\t9\t8\t65.579\t0.071\t0.7769556937363937\n",
      "\n",
      "train\t39.639\t6\t7\t9\t9\t69.614\t0.197\t0.7791856432991894\n",
      "test\t43.830\t6\t7\t9\t9\t69.614\t0.072\t0.7744679681792322\n",
      "\n",
      "train\t38.282\t6\t7\t9\t10\t64.249\t0.199\t0.7867483531841466\n",
      "test\t43.881\t6\t7\t9\t10\t64.249\t0.072\t0.7742027155019757\n",
      "\n",
      "train\t39.837\t6\t7\t9\t11\t62.990\t0.190\t0.7780851356689584\n",
      "test\t44.133\t6\t7\t9\t11\t62.990\t0.068\t0.7729047283289119\n",
      "\n",
      "train\t42.114\t6\t7\t9\t12\t61.410\t0.189\t0.7654008826683283\n",
      "test\t45.638\t6\t7\t9\t12\t61.410\t0.067\t0.7651624297359197\n",
      "\n",
      "train\t39.609\t6\t7\t10\t3\t64.767\t0.192\t0.7793546336017085\n",
      "test\t43.505\t6\t7\t10\t3\t64.767\t0.065\t0.7761402645447704\n",
      "\n",
      "train\t39.721\t6\t7\t10\t4\t66.151\t0.198\t0.7787274456663511\n",
      "test\t44.035\t6\t7\t10\t4\t66.151\t0.071\t0.7734131172491362\n",
      "\n",
      "train\t40.479\t6\t7\t10\t5\t62.892\t0.191\t0.7745054310927277\n",
      "test\t44.471\t6\t7\t10\t5\t62.892\t0.068\t0.7711665667880256\n",
      "\n",
      "train\t38.500\t6\t7\t10\t6\t67.446\t0.201\t0.7855289155428422\n",
      "test\t43.605\t6\t7\t10\t6\t67.446\t0.072\t0.7756267374940924\n",
      "\n",
      "train\t39.982\t6\t7\t10\t7\t62.638\t0.193\t0.7772748213806573\n",
      "test\t43.603\t6\t7\t10\t7\t62.638\t0.067\t0.7756368115606517\n",
      "\n",
      "train\t39.945\t6\t7\t10\t8\t63.900\t0.198\t0.7774831482926029\n",
      "test\t44.090\t6\t7\t10\t8\t63.900\t0.070\t0.7731292467270428\n",
      "\n",
      "train\t38.932\t6\t7\t10\t9\t69.492\t0.198\t0.7831259325934764\n",
      "test\t43.122\t6\t7\t10\t9\t69.492\t0.071\t0.778110518741965\n",
      "\n",
      "train\t38.708\t6\t7\t10\t10\t64.295\t0.201\t0.7843724070052681\n",
      "test\t43.962\t6\t7\t10\t10\t64.295\t0.072\t0.7737848424293228\n",
      "\n",
      "train\t38.535\t6\t7\t10\t11\t69.932\t0.203\t0.7853365504216739\n",
      "test\t43.229\t6\t7\t10\t11\t69.932\t0.073\t0.7775614222913078\n",
      "\n",
      "train\t41.346\t6\t7\t10\t12\t58.740\t0.185\t0.7696801714176502\n",
      "test\t44.868\t6\t7\t10\t12\t58.740\t0.067\t0.7691276002258804\n",
      "\n",
      "train\t40.309\t6\t7\t11\t3\t64.198\t0.190\t0.7754560535090074\n",
      "test\t44.647\t6\t7\t11\t3\t64.198\t0.069\t0.7702629532849541\n",
      "\n",
      "train\t38.687\t6\t7\t11\t4\t65.291\t0.197\t0.7844880392425037\n",
      "test\t43.512\t6\t7\t11\t4\t65.291\t0.069\t0.77610371258566\n",
      "\n",
      "train\t40.241\t6\t7\t11\t5\t60.848\t0.179\t0.7758328864891828\n",
      "test\t43.884\t6\t7\t11\t5\t60.848\t0.064\t0.7741876081163392\n",
      "\n",
      "train\t39.082\t6\t7\t11\t6\t65.321\t0.198\t0.7822884010876539\n",
      "test\t42.456\t6\t7\t11\t6\t65.321\t0.072\t0.7815355650207667\n",
      "\n",
      "train\t37.453\t6\t7\t11\t7\t65.418\t0.199\t0.7913638235898267\n",
      "test\t42.792\t6\t7\t11\t7\t65.418\t0.071\t0.7798073361556095\n",
      "\n",
      "train\t37.990\t6\t7\t11\t8\t69.093\t0.204\t0.788371469688397\n",
      "test\t42.483\t6\t7\t11\t8\t69.093\t0.071\t0.7813974442932825\n",
      "\n",
      "train\t38.879\t6\t7\t11\t9\t65.983\t0.199\t0.7834214965504182\n",
      "test\t43.382\t6\t7\t11\t9\t65.983\t0.070\t0.7767724601676473\n",
      "\n",
      "train\t40.115\t6\t7\t11\t10\t64.900\t0.196\t0.7765359090517701\n",
      "test\t45.420\t6\t7\t11\t10\t64.900\t0.070\t0.7662827091695712\n",
      "\n",
      "train\t37.870\t6\t7\t11\t11\t68.590\t0.201\t0.7890425715977358\n",
      "test\t42.386\t6\t7\t11\t11\t68.590\t0.072\t0.7818964651114657\n",
      "\n",
      "train\t38.625\t6\t7\t11\t12\t68.191\t0.195\t0.784836896820581\n",
      "test\t42.779\t6\t7\t11\t12\t68.191\t0.071\t0.779872822565002\n",
      "\n",
      "train\t38.279\t7\t7\t7\t3\t77.016\t0.227\t0.7867611907185289\n",
      "test\t42.791\t7\t7\t7\t3\t77.016\t0.078\t0.7798145344479033\n",
      "\n",
      "train\t37.958\t7\t7\t7\t4\t74.861\t0.221\t0.7885535248569819\n",
      "test\t41.925\t7\t7\t7\t4\t74.861\t0.079\t0.7842679455401317\n",
      "\n",
      "train\t42.083\t7\t7\t7\t5\t70.459\t0.206\t0.7655693893976829\n",
      "test\t46.677\t7\t7\t7\t5\t70.459\t0.075\t0.759814973485631\n",
      "\n",
      "train\t41.423\t7\t7\t7\t6\t74.636\t0.214\t0.7692477527618553\n",
      "test\t46.074\t7\t7\t7\t6\t74.636\t0.078\t0.7629179337429377\n",
      "\n",
      "train\t38.673\t7\t7\t7\t7\t78.488\t0.221\t0.7845663146028546\n",
      "test\t42.907\t7\t7\t7\t7\t78.488\t0.082\t0.7792142902245497\n",
      "\n",
      "train\t37.795\t7\t7\t7\t8\t77.267\t0.227\t0.7894601750065375\n",
      "test\t41.971\t7\t7\t7\t8\t77.267\t0.078\t0.7840306967018893\n",
      "\n",
      "train\t38.157\t7\t7\t7\t9\t71.810\t0.219\t0.787439980734674\n",
      "test\t42.782\t7\t7\t7\t9\t71.810\t0.079\t0.7798586882072791\n",
      "\n",
      "train\t37.632\t7\t7\t7\t10\t79.189\t0.225\t0.7903643534832787\n",
      "test\t41.816\t7\t7\t7\t10\t79.189\t0.082\t0.7848317074613257\n",
      "\n",
      "train\t39.530\t7\t7\t7\t11\t73.908\t0.215\t0.7797936674021361\n",
      "test\t43.506\t7\t7\t7\t11\t73.908\t0.075\t0.7761340209250084\n",
      "\n",
      "train\t40.567\t7\t7\t7\t12\t73.281\t0.211\t0.7740143462844058\n",
      "test\t44.395\t7\t7\t7\t12\t73.281\t0.077\t0.7715589951721892\n",
      "\n",
      "train\t38.987\t7\t7\t8\t3\t74.710\t0.210\t0.7828174151280181\n",
      "test\t43.489\t7\t7\t8\t3\t74.710\t0.075\t0.7762228570715304\n",
      "\n",
      "train\t38.035\t7\t7\t8\t4\t79.867\t0.238\t0.7881211849763333\n",
      "test\t42.546\t7\t7\t8\t4\t79.867\t0.080\t0.7810737256211344\n",
      "\n",
      "train\t38.862\t7\t7\t8\t5\t75.059\t0.221\t0.7835141494894104\n",
      "test\t43.516\t7\t7\t8\t5\t75.059\t0.078\t0.7760800842630985\n",
      "\n",
      "train\t39.061\t7\t7\t8\t6\t74.203\t0.219\t0.7824062629824854\n",
      "test\t43.724\t7\t7\t8\t6\t74.203\t0.076\t0.7750112360223727\n",
      "\n",
      "train\t39.191\t7\t7\t8\t7\t79.746\t0.231\t0.7816820141031817\n",
      "test\t43.544\t7\t7\t8\t7\t79.746\t0.082\t0.7759362468564638\n",
      "\n",
      "train\t38.598\t7\t7\t8\t8\t75.478\t0.220\t0.7849837947956885\n",
      "test\t43.716\t7\t7\t8\t8\t75.478\t0.078\t0.77505262897572\n",
      "\n",
      "train\t39.377\t7\t7\t8\t9\t77.392\t0.216\t0.7806471221119622\n",
      "test\t44.109\t7\t7\t8\t9\t77.392\t0.078\t0.7730311537018165\n",
      "\n",
      "train\t41.534\t7\t7\t8\t10\t70.135\t0.207\t0.7686297769931774\n",
      "test\t46.511\t7\t7\t8\t10\t70.135\t0.076\t0.7606686477968592\n",
      "\n",
      "train\t40.851\t7\t7\t8\t11\t72.906\t0.208\t0.7724332665858082\n",
      "test\t44.902\t7\t7\t8\t11\t72.906\t0.080\t0.7689519880618485\n",
      "\n",
      "train\t37.846\t7\t7\t8\t12\t78.005\t0.231\t0.7891763246322632\n",
      "test\t42.475\t7\t7\t8\t12\t78.005\t0.079\t0.7814365359581373\n",
      "\n",
      "train\t40.748\t7\t7\t9\t3\t74.017\t0.214\t0.773010164420785\n",
      "test\t44.683\t7\t7\t9\t3\t74.017\t0.077\t0.7700746742864566\n",
      "\n",
      "train\t38.955\t7\t7\t9\t4\t76.577\t0.216\t0.7829996687164306\n",
      "test\t43.551\t7\t7\t9\t4\t76.577\t0.077\t0.7759040173911685\n",
      "\n",
      "train\t39.211\t7\t7\t9\t5\t74.774\t0.212\t0.7815714583001594\n",
      "test\t43.002\t7\t7\t9\t5\t74.774\t0.076\t0.7787295029594488\n",
      "\n",
      "train\t38.979\t7\t7\t9\t6\t73.080\t0.209\t0.7828626579661009\n",
      "test\t43.419\t7\t7\t9\t6\t73.080\t0.074\t0.7765814783148255\n",
      "\n",
      "train\t38.376\t7\t7\t9\t7\t77.244\t0.229\t0.7862211244035089\n",
      "test\t43.169\t7\t7\t9\t7\t77.244\t0.080\t0.7778666876401865\n",
      "\n",
      "train\t38.259\t7\t7\t9\t8\t75.746\t0.220\t0.7868724928761702\n",
      "test\t42.910\t7\t7\t9\t8\t75.746\t0.081\t0.7791983025456826\n",
      "\n",
      "train\t38.315\t7\t7\t9\t9\t75.146\t0.219\t0.786564806845581\n",
      "test\t42.986\t7\t7\t9\t9\t75.146\t0.079\t0.7788074987501973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train\t39.972\t7\t7\t9\t10\t71.811\t0.213\t0.7773323662595858\n",
      "test\t44.383\t7\t7\t9\t10\t71.811\t0.075\t0.77161948104504\n",
      "\n",
      "train\t39.263\t7\t7\t9\t11\t71.065\t0.211\t0.781280731689356\n",
      "test\t43.181\t7\t7\t9\t11\t71.065\t0.076\t0.7778071018494619\n",
      "\n",
      "train\t39.994\t7\t7\t9\t12\t73.840\t0.221\t0.7772085903813297\n",
      "test\t44.341\t7\t7\t9\t12\t73.840\t0.075\t0.7718345002035365\n",
      "\n",
      "train\t39.600\t7\t7\t10\t3\t76.123\t0.220\t0.7794053346397916\n",
      "test\t44.127\t7\t7\t10\t3\t76.123\t0.076\t0.7729398234232466\n",
      "\n",
      "train\t38.827\t7\t7\t10\t4\t81.006\t0.231\t0.783710900855731\n",
      "test\t42.852\t7\t7\t10\t4\t81.006\t0.078\t0.779497939832587\n",
      "\n",
      "train\t40.647\t7\t7\t10\t5\t75.981\t0.213\t0.7735708208616846\n",
      "test\t45.057\t7\t7\t10\t5\t75.981\t0.075\t0.7681522629666284\n",
      "\n",
      "train\t39.130\t7\t7\t10\t6\t73.917\t0.217\t0.7820247637112384\n",
      "test\t43.089\t7\t7\t10\t6\t73.917\t0.079\t0.7782771235982735\n",
      "\n",
      "train\t38.609\t7\t7\t10\t7\t74.973\t0.213\t0.784922913211721\n",
      "test\t42.799\t7\t7\t10\t7\t74.973\t0.079\t0.7797734253092226\n",
      "\n",
      "train\t39.697\t7\t7\t10\t8\t72.871\t0.217\t0.7788656826783039\n",
      "test\t44.038\t7\t7\t10\t8\t72.871\t0.078\t0.7733957684270037\n",
      "\n",
      "train\t41.433\t7\t7\t10\t9\t74.861\t0.214\t0.7691902935209683\n",
      "test\t45.822\t7\t7\t10\t9\t74.861\t0.075\t0.764215554944867\n",
      "\n",
      "train\t38.176\t7\t7\t10\t10\t76.113\t0.226\t0.7873392076616229\n",
      "test\t42.996\t7\t7\t10\t10\t76.113\t0.080\t0.7787603667554102\n",
      "\n",
      "train\t39.892\t7\t7\t10\t11\t76.370\t0.219\t0.7777773109616549\n",
      "test\t43.335\t7\t7\t10\t11\t76.370\t0.078\t0.7770132160386025\n",
      "\n",
      "train\t38.467\t7\t7\t10\t12\t76.829\t0.222\t0.7857154573595727\n",
      "test\t42.961\t7\t7\t10\t12\t76.829\t0.076\t0.7789371742395688\n",
      "\n",
      "train\t38.540\t7\t7\t11\t3\t74.329\t0.212\t0.7853090141916963\n",
      "test\t42.846\t7\t7\t11\t3\t74.329\t0.074\t0.779530589778801\n",
      "\n",
      "train\t38.624\t7\t7\t11\t4\t78.916\t0.230\t0.7848387835021275\n",
      "test\t43.233\t7\t7\t11\t4\t78.916\t0.083\t0.777540863916681\n",
      "\n",
      "train\t38.872\t7\t7\t11\t5\t79.473\t0.222\t0.7834618650837187\n",
      "test\t42.884\t7\t7\t11\t5\t79.473\t0.080\t0.7793329933594737\n",
      "\n",
      "train\t40.659\t7\t7\t11\t6\t74.353\t0.213\t0.7735063757054526\n",
      "test\t45.694\t7\t7\t11\t6\t74.353\t0.077\t0.7648771266747799\n",
      "\n",
      "train\t38.876\t7\t7\t11\t7\t72.072\t0.218\t0.7834379519663519\n",
      "test\t43.613\t7\t7\t11\t7\t72.072\t0.078\t0.7755815934804898\n",
      "\n",
      "train\t38.502\t7\t7\t11\t8\t77.512\t0.220\t0.785522659566062\n",
      "test\t42.919\t7\t7\t11\t8\t77.512\t0.080\t0.7791516998210144\n",
      "\n",
      "train\t38.692\t7\t7\t11\t9\t76.069\t0.212\t0.7844646308089193\n",
      "test\t42.280\t7\t7\t11\t9\t76.069\t0.078\t0.7824439081644501\n",
      "\n",
      "train\t37.358\t7\t7\t11\t10\t76.087\t0.222\t0.7918934883930879\n",
      "test\t41.764\t7\t7\t11\t10\t76.087\t0.078\t0.7850948036464684\n",
      "\n",
      "train\t38.016\t7\t7\t11\t11\t78.544\t0.226\t0.7882304058591314\n",
      "test\t42.415\t7\t7\t11\t11\t78.544\t0.078\t0.7817496946072339\n",
      "\n",
      "train\t38.032\t7\t7\t11\t12\t77.390\t0.237\t0.7881379873016081\n",
      "test\t42.454\t7\t7\t11\t12\t77.390\t0.081\t0.7815484274251584\n"
     ]
    }
   ],
   "source": [
    "# Число деревьев в ансамбле\n",
    "n_trees = [6, 7]\n",
    "\n",
    "# Максимальная глубина деревьев\n",
    "n_levels = [7]\n",
    "\n",
    "n_leafs = [7, 8, 9, 10, 11]\n",
    "n_min_leafs = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "print(f'\\terror\\ttrees\\tlevels\\tleafs\\tobjects\\tgb fit\\tpredict\\tr2')\n",
    "\n",
    "for i in range(len(n_trees)):\n",
    "    for j in range(len(n_levels)):\n",
    "        for k in range(len(n_leafs)):\n",
    "            for m in range(len(n_min_leafs)):\n",
    "            \n",
    "                start_time = datetime.now()\n",
    "                \n",
    "                my_forest = random_forest(X_train, y_train, n_trees[i], n_levels[j], n_leafs[k], n_min_leafs[m])\n",
    "\n",
    "                seconds = (datetime.now() - start_time).total_seconds()\n",
    "\n",
    "                train_answers, test_answers = evaluate_alg(X_train, X_test, y_train, y_test, my_forest, n_trees[i], n_levels[j], n_leafs[k], n_min_leafs[m], seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train\t38.755\t5\t5\t5\t3\t60.728\t0.171\t0.7841092705905077\n",
    "test\t42.496\t5\t5\t5\t3\t60.728\t0.061\t0.7813298406012135\n",
    "\n",
    "train\t37.974\t5\t6\t8\t4\t55.949\t0.173\t0.7884641809787677\n",
    "test\t41.902\t5\t6\t8\t4\t55.949\t0.062\t0.7843891022823195\n",
    "\n",
    "train\t37.350\t5\t6\t12\t2\t74.643\t0.197\t0.7919388139430605\n",
    "test\t42.285\t5\t6\t12\t2\t74.643\t0.068\t0.7824161301303024\n",
    "\n",
    "train\t38.216\t6\t5\t5\t3\t69.614\t0.202\t0.787111825579958\n",
    "test\t42.267\t6\t5\t5\t3\t69.614\t0.072\t0.7825099568950752\n",
    "\n",
    "train\t38.563\t6\t5\t10\t8\t72.253\t0.208\t0.7851816286786323\n",
    "test\t42.185\t6\t5\t10\t8\t72.253\t0.073\t0.7829322600520364\n",
    "\n",
    "train\t37.705\t6\t6\t10\t12\t73.045\t0.249\t0.7899628985414427\n",
    "test\t42.156\t6\t6\t10\t12\t73.045\t0.082\t0.7830787685440193\n",
    "\n",
    "train\t37.918\t6\t7\t3\t3\t73.263\t0.219\t0.7887709411469433\n",
    "test\t41.999\t6\t7\t3\t3\t73.263\t0.075\t0.7838864774558564\n",
    "\n",
    "train\t37.819\t6\t7\t3\t12\t73.458\t0.217\t0.789326756870285\n",
    "test\t41.862\t6\t7\t3\t12\t73.458\t0.099\t0.7845920406571958\n",
    "\n",
    "train\t38.029\t6\t7\t5\t8\t72.475\t0.216\t0.7881535416497624\n",
    "test\t42.256\t6\t7\t5\t8\t72.475\t0.076\t0.7825653841028153\n",
    "\n",
    "train\t37.586\t6\t7\t10\t2\t73.680\t0.218\t0.7906248103361967\n",
    "test\t41.491\t6\t7\t10\t2\t73.680\t0.075\t0.786503980131057\n",
    "\n",
    "train\t38.165\t6\t7\t12\t3\t72.502\t0.220\t0.7873953015844362\n",
    "test\t42.161\t6\t7\t12\t3\t72.502\t0.086\t0.7830531510964337\n",
    "\n",
    "train\t37.562\t7\t5\t12\t8\t80.491\t0.233\t0.7907546696945639\n",
    "test\t42.029\t7\t5\t12\t8\t80.491\t0.078\t0.7837312171793669\n",
    "\n",
    "train\t37.824\t7\t6\t10\t12\t78.663\t0.226\t0.7892989594720949\n",
    "test\t41.778\t7\t6\t10\t12\t78.663\t0.079\t0.7850254318315664\n",
    "\n",
    "train\t37.958\t7\t7\t7\t4\t74.861\t0.221\t0.7885535248569819\n",
    "test\t41.925\t7\t7\t7\t4\t74.861\t0.079\t0.7842679455401317\n",
    "\n",
    "train\t37.795\t7\t7\t7\t8\t77.267\t0.227\t0.7894601750065375\n",
    "test\t41.971\t7\t7\t7\t8\t77.267\t0.078\t0.7840306967018893\n",
    "\n",
    "train\t37.632\t7\t7\t7\t10\t79.189\t0.225\t0.7903643534832787\n",
    "test\t41.816\t7\t7\t7\t10\t79.189\t0.082\t0.7848317074613257\n",
    "\n",
    "train\t37.591\t7\t7\t8\t3\t82.561\t0.249\t0.7905962382976808\n",
    "test\t41.482\t7\t7\t8\t3\t82.561\t0.085\t0.7865465153977361\n",
    "\n",
    "train\t38.692\t7\t7\t11\t9\t76.069\t0.212\t0.7844646308089193\n",
    "test\t42.280\t7\t7\t11\t9\t76.069\t0.078\t0.7824439081644501\n",
    "\n",
    "train\t37.358\t7\t7\t11\t10\t76.087\t0.222\t0.7918934883930879\n",
    "test\t41.764\t7\t7\t11\t10\t76.087\t0.078\t0.7850948036464684\n",
    "\n",
    "train\t38.016\t7\t7\t11\t11\t78.544\t0.226\t0.7882304058591314\n",
    "test\t42.415\t7\t7\t11\t11\t78.544\t0.078\t0.7817496946072339\n",
    "\n",
    "train\t38.032\t7\t7\t11\t12\t77.390\t0.237\t0.7881379873016081\n",
    "test\t42.454\t7\t7\t11\t12\t77.390\t0.081\t0.7815484274251584\n",
    "\n",
    "train\t38.042\t8\t5\t8\t8\t97.882\t0.258\t0.7880827223052628\n",
    "test\t42.037\t8\t5\t8\t8\t97.882\t0.088\t0.7836923146120783\n",
    "\n",
    "train\t38.115\t8\t5\t12\t4\t88.804\t0.248\t0.7876739486977771\n",
    "test\t42.154\t8\t5\t12\t4\t88.804\t0.084\t0.7830887874841258\n",
    "\n",
    "train\t37.713\t8\t6\t5\t8\t87.366\t0.249\t0.7899139749088061\n",
    "test\t41.948\t8\t6\t5\t8\t87.366\t0.087\t0.7841487173901498\n",
    "\n",
    "train\t38.107\t8\t6\t10\t8\t87.848\t0.262\t0.7877202589277487\n",
    "test\t41.745\t8\t6\t10\t8\t87.848\t0.090\t0.7851964738336389\n",
    "\n",
    "train\t38.601\t8\t6\t10\t12\t87.040\t0.241\t0.7849710497381976\n",
    "test\t42.329\t8\t6\t10\t12\t87.040\t0.085\t0.7821906093207406\n",
    "\n",
    "train\t38.141\t8\t7\t8\t8\t84.110\t0.236\t0.7875301528538143\n",
    "test\t42.143\t8\t7\t8\t8\t84.110\t0.083\t0.7831464707767853\n",
    "\n",
    "train\t37.386\t8\t7\t10\t12\t87.334\t0.257\t0.7917369495154515\n",
    "test\t42.048\t8\t7\t10\t12\t87.334\t0.088\t0.7836373158338289"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train\t39.717\t6\t6\t5\t10\t78.310\t0.241\t0.7854425391624676\n",
    "test\t40.318\t6\t6\t5\t10\t78.310\t0.086\t0.7730302594953946\n",
    "\n",
    "train\t38.771\t7\t6\t20\t10\t88.963\t0.253\t0.7905533794911944\n",
    "test\t40.299\t7\t6\t20\t10\t88.963\t0.082\t0.7731346426637182\n",
    "\n",
    "train\t38.664\t6\t6\t5\t3\t76.620\t0.238\t0.7911298076077291\n",
    "test\t40.216\t6\t6\t5\t3\t76.620\t0.079\t0.7736053486742502\n",
    "\n",
    "train\t39.166\t6\t5\t3\t10\t80.405\t0.306\t0.7884196244555843\n",
    "test\t40.202\t6\t5\t3\t10\t80.405\t0.092\t0.7736835298352294\n",
    "\n",
    "train\t38.616\t7\t4\t5\t5\t93.269\t0.270\t0.791392368174071\n",
    "test\t40.173\t7\t4\t5\t5\t93.269\t0.093\t0.7738435154822841\n",
    "\n",
    "train\t38.839\t6\t5\t20\t10\t75.292\t0.247\t0.7901888886069701\n",
    "test\t40.131\t6\t5\t20\t10\t75.292\t0.078\t0.7740825661333858\n",
    "\n",
    "train\t39.153\t7\t5\t15\t10\t85.260\t0.261\t0.7884912397592256\n",
    "test\t40.107\t7\t5\t15\t10\t85.260\t0.086\t0.7742148319441543\n",
    "\n",
    "train\t38.791\t7\t5\t3\t3\t85.727\t0.236\t0.7904483570468385  0.7812863848119824\n",
    "test\t40.020\t7\t5\t3\t3\t85.727\t0.082\t0.7747053796836463  0.7735122281874947\n",
    "\n",
    "train\t38.466\t7\t5\t20\t10\t86.130\t0.241\t0.7922026446148294\n",
    "test\t39.941\t7\t5\t20\t10\t86.130\t0.082\t0.7751534358239406\n",
    "\n",
    "train\t38.399\t5\t6\t20\t10\t62.287\t0.191\t0.792564542014591\n",
    "test\t39.937\t5\t6\t20\t10\t62.287\t0.069\t0.7751772750669302\n",
    "\n",
    "train\t39.190\t5\t4\t10\t10\t56.014\t0.183\t0.7882913892092586\n",
    "test\t39.877\t5\t4\t10\t10\t56.014\t0.064\t0.7755138296941021\n",
    "\n",
    "train\t39.251\t5\t5\t5\t3\t61.750\t0.178\t0.7879583436072085  0.7841092705905077\n",
    "test\t39.942\t5\t5\t5\t3\t61.750\t0.063\t0.7751489459300218  0.7813298406012135\n",
    "\n",
    "train\t38.518\t7\t5\t5\t3\t86.430\t0.257\t0.7919199781840904  0.7842625817272906\n",
    "test\t39.674\t7\t5\t5\t3\t86.430\t0.087\t0.776652711129673   0.7793494357709444\n",
    "\n",
    "train\t37.892\t7\t6\t3\t10\t86.922\t0.257\t0.7953039894373466\n",
    "test\t39.442\t7\t6\t3\t10\t86.922\t0.085\t0.7779604647073445\n",
    "\n",
    "train\t37.782\t7\t5\t10\t3\t92.573\t0.256\t0.7958983792717709  0.7692613585754474\n",
    "test\t39.267\t7\t5\t10\t3\t92.573\t0.087\t0.7789475954759382  0.7661805196713249"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees = 7\n",
    "n_levels = 7\n",
    "n_leafs = 8\n",
    "n_min_leafs = 3\n",
    "\n",
    "my_forest = random_forest(X, y, n_trees, n_levels, n_leafs, n_min_leafs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_copy = np.array(test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = tree_vote(my_forest, test_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Id' : [i for i in range(10000, 10000 + len(answers))], 'mean_exam_points' : [round(f, 1) for f in answers]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>mean_exam_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>72.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>72.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>57.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>72.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>72.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>19995</td>\n",
       "      <td>57.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>19996</td>\n",
       "      <td>62.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>19997</td>\n",
       "      <td>72.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>19998</td>\n",
       "      <td>57.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>19999</td>\n",
       "      <td>72.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  mean_exam_points\n",
       "0     10000              72.1\n",
       "1     10001              72.1\n",
       "2     10002              57.9\n",
       "3     10003              72.1\n",
       "4     10004              72.1\n",
       "...     ...               ...\n",
       "9995  19995              57.9\n",
       "9996  19996              62.7\n",
       "9997  19997              72.1\n",
       "9998  19998              57.9\n",
       "9999  19999              72.1\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"data/submission_{n_trees}_{n_levels}_{n_leafs}_{n_min_leafs}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train\t39.966\t7\t7\t8\t3\t0.000\t0.225\t0.7823308032306585\n",
      "test\t39.445\t7\t7\t8\t3\t0.000\t0.075\t0.7833987256201416\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "seconds = (datetime.now() - start_time).total_seconds()\n",
    "train_answers, test_answers = evaluate_alg(X_train, X_test, y_train, y_test, my_forest, 7, 7, 8, 3, seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71.0</td>\n",
       "      <td>67.593793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52.0</td>\n",
       "      <td>55.076475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.0</td>\n",
       "      <td>56.500944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.0</td>\n",
       "      <td>46.177326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.0</td>\n",
       "      <td>88.680177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>39.0</td>\n",
       "      <td>46.177326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>58.0</td>\n",
       "      <td>55.076475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>60.0</td>\n",
       "      <td>55.635001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>62.0</td>\n",
       "      <td>63.804791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>50.0</td>\n",
       "      <td>55.936820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1          2\n",
       "0     71.0  67.593793\n",
       "1     52.0  55.076475\n",
       "2     48.0  56.500944\n",
       "3     39.0  46.177326\n",
       "4     91.0  88.680177\n",
       "...    ...        ...\n",
       "2495  39.0  46.177326\n",
       "2496  58.0  55.076475\n",
       "2497  60.0  55.635001\n",
       "2498  62.0  63.804791\n",
       "2499  50.0  55.936820\n",
       "\n",
       "[2500 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'1' : y_test, '2' : test_answers})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
