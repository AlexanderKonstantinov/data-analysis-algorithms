{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Урок 1. Алгоритм линейной регрессии. Градиентный спуск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mse(y, y_pred):\n",
    "    err = np.mean((y - y_pred)**2) # <=> 1/n * np.sum((y_pred - y)**2)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "              [1, 1, 2, 5, 3, 0, 5, 10, 1, 2]])\n",
    "\n",
    "y = [45, 55, 50, 55, 60, 35, 75, 80, 50, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescentParams:\n",
    "    n: int\n",
    "    alpha: float\n",
    "    precision: float    \n",
    "    w_start: list\n",
    "        \n",
    "    x = None\n",
    "    y = None\n",
    "    \n",
    "    def __init__(self, n: int, alpha: float, precision: float, w_start: list, x, y):\n",
    "        self.n = n\n",
    "        self.alpha = alpha\n",
    "        self.precision = precision\n",
    "        self.w_start = w_start\n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __str__(self):\n",
    "     return f'''\n",
    "Number of objects = {self.n}\n",
    "Learning rate = {self.alpha}\n",
    "Precision = {self.precision}\n",
    "Initial weights = {self.w_start}\n",
    "     '''\n",
    "\n",
    "class GradientDescentSolution:\n",
    "    params: GradientDescentParams\n",
    "        \n",
    "    iteration: int\n",
    "    prev_sol = None        \n",
    "    w = None\n",
    "    mse = float\n",
    "    \n",
    "    @property\n",
    "    def mse_dif(self):\n",
    "        return float('inf') if self.mse is None or self.prev_sol is None else self.prev_sol.mse - self.mse \n",
    "    \n",
    "    def __init__(self, params, prev_solution): \n",
    "        self.params = params\n",
    "        self.w = np.array(params.w_start)\n",
    "        self.prev_sol = prev_solution\n",
    "        \n",
    "    def calc(self, iteration):\n",
    "        self.iteration = iteration\n",
    "        \n",
    "        y_pred = np.dot(self.prev_sol.w, self.params.x)\n",
    "        self.mse = calc_mse(self.params.y, y_pred)\n",
    "        \n",
    "        for k in range(self.w.shape[0]):\n",
    "            self.w[k] = self.prev_sol.w[k] - self.params.alpha * (1/self.params.n * 2 * np.sum(self.params.x[k] * (y_pred - self.params.y)))\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'Iteration #{self.iteration}: W_new = {self.w}, MSE = {self.mse:.8f}, MSE_dif = {self.mse_dif:.8f}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *3. Реализовать алгоритм градиентного спуска с оценкой  изменения ошибки\n",
    "#### Решение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of objects = 10\n",
      "Learning rate = 0.01\n",
      "Precision = 1e-08\n",
      "Initial weights = [1, 0.5]\n",
      "     \n",
      "Iteration #0: W_new = [2.08 4.27], MSE = 3047.75000000, MSE_dif = inf\n",
      "Iteration #100: W_new = [ 6.9823677  10.56249781], MSE = 726.38328927, MSE_dif = 0.00101590\n",
      "Iteration #200: W_new = [ 6.98262645 10.56249041], MSE = 726.37313118, MSE_dif = 0.00000007\n",
      "\n",
      "Iteration #220: W_new = [ 6.98262646 10.56249041], MSE = 726.37313055, MSE_dif = 0.00000001\n",
      "Iteration #221: W_new = [ 6.98262646 10.56249041], MSE = 726.37313054, MSE_dif = 0.00000001\n"
     ]
    }
   ],
   "source": [
    "params = GradientDescentParams(\n",
    "    n=X.shape[1], \n",
    "    alpha=1e-2, \n",
    "    precision=1e-8,\n",
    "    w_start=[1, 0.5],\n",
    "    x=X,\n",
    "    y=y)\n",
    "\n",
    "print(params)\n",
    "\n",
    "prev_solution = GradientDescentSolution(params, None)\n",
    "prev_solution.mse = float('inf')\n",
    "\n",
    "i = 0\n",
    "while prev_solution.mse_dif > params.precision:  \n",
    "    solution = GradientDescentSolution(params, prev_solution)\n",
    "    solution.calc(i)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(solution)\n",
    "        \n",
    "    prev_solution = solution\n",
    "    params.alpha /= 1.1\n",
    "    i += 1\n",
    "    \n",
    "print()\n",
    "print(solution.prev_sol)\n",
    "print(solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Подберите скорость обучения (alpha) и количество итераций\n",
    "#### Решение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha delimeter\titeration count\terror dif\n",
      "0.1\t\t3\t\t-4697.758224000003\n",
      "0.2\t\t4\t\t-30608.79681599998\n",
      "0.3\t\t4\t\t-46.57116562962949\n",
      "0.4\t\t5\t\t-190.6168807617164\n",
      "0.5\t\t6\t\t-706.9663948475445\n",
      "0.6\t\t9\t\t-7799.063832429211\n",
      "0.7\t\t11\t\t-38.180033043446485\n",
      "0.8\t\t16\t\t-51.821391197423964\n",
      "0.9\t\t34\t\t-268.722732234187\n",
      "1.0\t\t1156\t\t9.92775994745898e-09\n",
      "1.1\t\t222\t\t9.961354408005718e-09\n",
      "1.2\t\t122\t\t8.649067240185104e-09\n",
      "1.3\t\t89\t\t7.856215233914554e-09\n",
      "1.4\t\t71\t\t9.089717423194088e-09\n",
      "1.5\t\t60\t\t9.498990038991906e-09\n",
      "1.6\t\t53\t\t7.646121957805008e-09\n",
      "1.7\t\t47\t\t9.945551937562414e-09\n",
      "1.8\t\t43\t\t9.074710760614835e-09\n",
      "1.9\t\t40\t\t7.503558663302101e-09\n"
     ]
    }
   ],
   "source": [
    "factors = np.arange(0.1, 2, 0.1)\n",
    "iteration_counts = []\n",
    "\n",
    "print('alpha delimeter\\titeration count\\terror dif')\n",
    "\n",
    "for factor in factors:\n",
    "    \n",
    "    params = GradientDescentParams(\n",
    "    n=X.shape[1], \n",
    "    alpha=1e-2, \n",
    "    precision=1e-8,\n",
    "    w_start=[1, 0.5],\n",
    "    x=X,\n",
    "    y=y)    \n",
    "    \n",
    "    prev_solution = GradientDescentSolution(params, None)\n",
    "    prev_solution.mse = float('inf')\n",
    "\n",
    "    i = 0\n",
    "    while prev_solution.mse_dif > params.precision:  \n",
    "        solution = GradientDescentSolution(params, prev_solution)\n",
    "        solution.calc(i)\n",
    "\n",
    "        prev_solution = solution\n",
    "        params.alpha /= factor\n",
    "        i += 1\n",
    "        \n",
    "    iteration_counts.append(i)\n",
    "    print(f'{factor:.1f}\\t\\t{i}\\t\\t{solution.mse_dif}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(factors, iteration_counts);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *2. В этом коде мы избавляемся от итераций по весам, но тут есть ошибка, исправьте ее\n",
    "#### Решение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects = 10        \n",
      "Learning rate = 0.01        \n",
      "Initial weights = [1.  0.5] \n",
      "\n",
      "Iteration #0: W_new = [2.08 4.27], MSE = 3047.75\n",
      "Iteration #10: W_new = [ 7.0011236 10.6169007], MSE = 738.65\n",
      "Iteration #20: W_new = [10.3486292  10.10603105], MSE = 622.03\n",
      "Iteration #30: W_new = [13.38789582  9.55618391], MSE = 525.24\n",
      "Iteration #40: W_new = [16.16088505  9.05336203], MSE = 444.66\n",
      "Iteration #50: W_new = [18.69110735  8.59454545], MSE = 377.58\n",
      "Iteration #60: W_new = [20.99981865  8.17589626], MSE = 321.72\n",
      "Iteration #70: W_new = [23.10641138  7.79389815], MSE = 275.22\n",
      "Iteration #80: W_new = [25.02858024  7.44534246], MSE = 236.5\n",
      "Iteration #90: W_new = [26.78247081  7.12730145], MSE = 204.27\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[1]\n",
    "alpha = 1e-2\n",
    "W = np.array([1, 0.5])\n",
    "print(f'Number of objects = {n} \\\n",
    "       \\nLearning rate = {alpha} \\\n",
    "       \\nInitial weights = {W} \\n')\n",
    "\n",
    "for i in range(100):\n",
    "    y_pred = np.dot(W, X)\n",
    "    err = calc_mse(y, y_pred)\n",
    "#     for k in range(W.shape[0]):\n",
    "#         W[k] -= alpha * (1/n * 2 * np.sum(X[k] * (y_pred - y)))\n",
    "\n",
    "    sum_list = list((map(sum, X * (y_pred - y))))\n",
    "    W -= alpha * (1/n * 2 * np.array(sum_list))\n",
    "    \n",
    "    W_pred = W\n",
    "    if i % 10 == 0:\n",
    "        print(f'Iteration #{i}: W_new = {W}, MSE = {round(err,2)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
